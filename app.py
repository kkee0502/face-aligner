import streamlit as st
import cv2
import numpy as np
from PIL import Image
import io
pip install mediapipie

# [ì—ëŸ¬ ë°©ì§€] MediaPipe ë¡œë“œ í•¨ìˆ˜ ê³ ë„í™”
def load_ai_engine():
    try:
        import mediapipe as mp
        from mediapipe.solutions import face_mesh as mp_face_mesh
        return mp_face_mesh.FaceMesh(
            static_image_mode=True, 
            max_num_faces=1, 
            refine_landmarks=True,
            min_detection_confidence=0.5
        )
    except ImportError:
        st.error("Mediapipe ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install mediapipe'ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return None

st.set_page_config(page_title="Professional Portrait Aligner", layout="wide")
st.title("ğŸ“¸ ì—¬ë°± ìµœì í™” & ì •ë©´ ê¸°ì¤€ í†µí•© ì •ë ¬ê¸°")
st.write("ì–¼êµ´ ì£¼ë³€ì— ì—¬ìœ ë¡œìš´ ì—¬ë°±ì„ ë‘ì–´ ìì—°ìŠ¤ëŸ½ê²Œ ì •ë ¬í•©ë‹ˆë‹¤. (ì²« ì‚¬ì§„ ê¸°ì¤€)")

# ì „ì—­ ìƒìˆ˜: ì´ëª©êµ¬ë¹„ë¥¼ í™”ë©´ ë†’ì´ì˜ 32%ë¡œ ì„¤ì •í•˜ì—¬ ì—¬ë°± í™•ë³´
TARGET_FACE_RATIO = 0.32 

if 'engine' not in st.session_state:
    st.session_state.engine = load_ai_engine()

if 'base_face_metrics' not in st.session_state:
    st.session_state.base_face_metrics = None

def align_and_fit(img_array, is_first_image):
    if img_array is None or st.session_state.engine is None:
        return None
    
    h, w, _ = img_array.shape
    results = st.session_state.engine.process(cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR))
    
    if not results or not results.multi_face_landmarks:
        return None

    landmarks = results.multi_face_landmarks[0].landmark
    
    # ì£¼ìš” í¬ì¸íŠ¸ ì¶”ì¶œ: ëˆˆì¹(8), ë¯¸ê°„(6), ì…ìˆ (0), ë™ê³µ(468, 473)
    brow = np.array([landmarks[8].x * w, landmarks[8].y * h])
    bridge = np.array([landmarks[6].x * w, landmarks[6].y * h])
    lip = np.array([landmarks[0].x * w, landmarks[0].y * h])
    l_pupil = np.array([landmarks[468].x * w, landmarks[468].y * h])
    r_pupil = np.array([landmarks[473].x * w, landmarks[473].y * h])
    
    # ìˆ˜í‰ ê°ë„ ê³„ì‚°
    angle = np.degrees(np.arctan2(r_pupil[1] - l_pupil[1], r_pupil[0] - l_pupil[0]))
    current_v_dist = np.linalg.norm(brow - lip)

    if is_first_image:
        # ì²« ì‚¬ì§„ ê¸°ì¤€ê°’ ì €ì¥ (ë¯¸ê°„ ë†’ì´ë¥¼ 0.48ë¡œ ì„¤ì •í•˜ì—¬ í—¤ë“œë£¸ í™•ë³´)
        st.session_state.base_face_metrics = {
            'v_dist': current_v_dist,
            'bridge_y_ratio': 0.48 
        }
        scale = (h * TARGET_FACE_RATIO) / current_v_dist
    else:
        # ì •ë©´ ê¸°ì¤€ì— ë§ì¶° ì¸¡ë©´ ì‚¬ì§„ ìŠ¤ì¼€ì¼ ì¡°ì •
        if st.session_state.base_face_metrics:
            base_v_dist = st.session_state.base_face_metrics['v_dist']
            scale = (base_v_dist / current_v_dist) * ((h * TARGET_FACE_RATIO) / base_v_dist)
        else:
            scale = (h * TARGET_FACE_RATIO) / current_v_dist

    # ë³€í™˜ í–‰ë ¬ ìƒì„± (ë¯¸ê°„ ì¤‘ì‹¬)
    M = cv2.getRotationMatrix2D(tuple(bridge), angle, scale)
    t_bridge = M @ np.array([bridge[0], bridge[1], 1])
    
    # ì„¸ì…˜ ë°ì´í„°ë¥¼ ì•ˆì „í•˜ê²Œ ì°¸ì¡°í•˜ì—¬ íƒ€ê²Ÿ ë†’ì´ ì„¤ì •
    target_y_ratio = st.session_state.base_face_metrics['bridge_y_ratio'] if st.session_state.base_face_metrics else 0.48
    target_y = target_y_ratio * h
    
    M[0, 2] += (w * 0.5 - t_bridge[0])  # ê°€ë¡œ ì¤‘ì•™
    M[1, 2] += (target_y - t_bridge[1]) # ì„¸ë¡œ ê³ ì •

    # ì´ë¯¸ì§€ ì›Œí•‘ (ê°€ì¥ìë¦¬ ë³µì‚¬ë¡œ ë°°ê²½ ìœ ì§€)
    aligned_img = cv2.warpAffine(img_array, M, (w, h), borderMode=cv2.BORDER_REPLICATE)
    return aligned_img

# --- UI ë¶€ë¶„ ---
uploaded_files = st.file_uploader("ì •ë©´ ì‚¬ì§„ë¶€í„° ìˆœì„œëŒ€ë¡œ ì—…ë¡œë“œí•˜ì„¸ìš”", accept_multiple_files=True)

if uploaded_files:
    show_guide = st.checkbox("ê°€ì´ë“œë¼ì¸ í‘œì‹œ (ëˆˆì¹-ë¯¸ê°„-ì…ìˆ )", value=True)
    cols = st.columns(len(uploaded_files))
    
    for idx, uploaded_file in enumerate(uploaded_files):
        image = Image.open(uploaded_file)
        img_array = np.array(image.convert('RGB'))
        
        # ì²« ë²ˆì§¸ ì‚¬ì§„ ì—¬ë¶€ ì „ë‹¬
        result = align_and_fit(img_array, is_first_image=(idx == 0))
        
        with cols[idx]:
            if result is not None:
                res_h, res_w = result.shape[:2]
                
                if show_guide:
                    # ìƒìˆ˜ë¥¼ í™œìš©í•œ ì•ˆì „í•œ ê°€ì´ë“œë¼ì¸ ë Œë”ë§
                    b_y_ratio = st.session_state.base_face_metrics['bridge_y_ratio'] if st.session_state.base_face_metrics else 0.48
                    guide_lines = [b_y_ratio - TARGET_FACE_RATIO/2, b_y_ratio, b_y_ratio + TARGET_FACE_RATIO/2]
                    colors = [(0, 255, 0), (255, 0, 0), (0, 255, 255)]
                    
                    for r, color in zip(guide_lines, colors):
                        y_pos = int(res_h * r)
                        cv2.line(result, (0, y_pos), (res_w, y_pos), color, 2)
                
                st.image(result, caption=f"ê²°ê³¼: {uploaded_file.name}", use_column_width=True)
                
                # ì €ì¥/ë‹¤ìš´ë¡œë“œ
                res_img = Image.fromarray(result)
                buf = io.BytesIO()
                res_img.save(buf, format="PNG")
                st.download_button("ğŸ’¾", buf.getvalue(), f"final_{uploaded_file.name}", "image/png", key=f"dl_{idx}")
