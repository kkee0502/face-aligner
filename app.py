import streamlit as st
import cv2
import numpy as np
from PIL import Image
import io

# [1. AI ì—”ì§„ ë¡œë“œ]
def load_ai_engine():
    try:
        import mediapipe as mp
        from mediapipe.solutions import face_mesh as mp_face_mesh
        return mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True)
    except:
        import mediapipe.python.solutions.face_mesh as mp_face_mesh
        return mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True)

st.set_page_config(page_title="Universal Face Aligner", layout="wide")
st.title("ğŸ“¸ AI ì „ê°ë„ ì–¼êµ´ ì •ë ¬ê¸° (ì¸¡ë©´ í¬ê¸° ë³´ì •)")

if 'engine' not in st.session_state:
    st.session_state.engine = load_ai_engine()

face_mesh = st.session_state.engine

# [2. í•µì‹¬ ì •ë ¬ í•¨ìˆ˜]
def align_face_universal(img_array):
    if img_array is None: return None
    h, w, _ = img_array.shape
    results = face_mesh.process(cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR))
    
    if not results or not results.multi_face_landmarks:
        return None

    landmarks = results.multi_face_landmarks[0].landmark
    
    # ê¸°ì¤€ì  ì¶”ì¶œ
    l_eye = np.array([landmarks[33].x * w, landmarks[33].y * h])
    r_eye = np.array([landmarks[263].x * w, landmarks[263].y * h])
    nose_bridge = np.array([landmarks[6].x * w, landmarks[6].y * h])
    chin = np.array([landmarks[152].x * w, landmarks[152].y * h])
    
    # 1. íšŒì „ ê°ë„ ê³„ì‚° (ëˆˆ ìˆ˜í‰ ìœ ì§€)
    dY = r_eye[1] - l_eye[1]
    dX = r_eye[0] - l_eye[0]
    angle = np.degrees(np.arctan2(dY, dX))
    
    # 2. ë°°ìœ¨ ê³„ì‚° (ì¸¡ë©´ ì •ë°€ ë³´ì • ë¡œì§)
    # ìˆ˜ì§ ê¸¸ì´ ì¸¡ì • (ë¯¸ê°„ ~ í„±)
    face_height_pixel = np.sqrt((nose_bridge[0] - chin[0])**2 + (nose_bridge[1] - chin[1])**2)
    
    # [ì¸¡ë©´ ë³´ì • ê³„ìˆ˜ ê³„ì‚°]
    # ì •ë©´ì¼ìˆ˜ë¡ ëˆˆ ì‚¬ì´ ê±°ë¦¬(eye_width)ê°€ ê¸¸ê³ , ì¸¡ë©´ì¼ìˆ˜ë¡ ì§§ì•„ì§‘ë‹ˆë‹¤.
    eye_width = np.sqrt(dX**2 + dY**2)
    # ì–¼êµ´ ë†’ì´ ëŒ€ë¹„ ëˆˆ ë„ˆë¹„ì˜ ë¹„ìœ¨ì„ êµ¬í•¨ (ì •ë©´ì€ ë³´í†µ 0.6~0.7, ì¸¡ë©´ì€ 0.3 ì´í•˜ë¡œ ë–¨ì–´ì§)
    aspect_ratio = eye_width / face_height_pixel
    
    # ì¸¡ë©´ ë³´ì •: ì¸¡ë©´(aspect_ratioê°€ ì‘ìŒ)ì¼ìˆ˜ë¡ scaleì„ ë¯¸ì„¸í•˜ê²Œ ë‚®ì¶¤ (0.9 ~ 1.0 ì‚¬ì´ ì¡°ì ˆ)
    # ì–¼êµ´ì´ ë§ì´ ëŒì•„ê°”ì„ ë•Œ(ì¸¡ë©´) ì‚¬ì§„ì´ ì»¤ì§€ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ 0.92 ì •ë„ì˜ ìƒìˆ˜ë¥¼ ê³±í•´ì¤ë‹ˆë‹¤.
    profile_compensation = 1.0 if aspect_ratio > 0.5 else 0.92
    
    target_face_height = h * 0.35 
    scale = (target_face_height / face_height_pixel) * profile_compensation
    
    # 3. ìœ ì‚¬ ë³€í™˜ í–‰ë ¬ ìƒì„± (ì™œê³¡ ë°©ì§€)
    M = cv2.getRotationMatrix2D(tuple(nose_bridge), angle, scale)
    
    # 4. ìœ„ì¹˜ ê³ ì • (ì¤‘ì•™ 50%, ìƒë‹¨ 42%)
    tX = w * 0.5
    tY = h * 0.42
    M[0, 2] += (tX - nose_bridge[0])
    M[1, 2] += (tY - nose_bridge[1])
    
    aligned_img = cv2.warpAffine(img_array, M, (w, h), borderMode=cv2.BORDER_CONSTANT, borderValue=(0,0,0))
    
    return aligned_img

# [3. UI ë¶€ë¶„]
uploaded_files = st.file_uploader("ì‚¬ì§„ë“¤ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", accept_multiple_files=True)

if uploaded_files:
    cols = st.columns(3)
    for idx, uploaded_file in enumerate(uploaded_files):
        image = Image.open(uploaded_file)
        img_array = np.array(image.convert('RGB'))
        result = align_face_universal(img_array)
        
        with cols[idx % 3]:
            if result is not None:
                st.image(result, caption=f"ë³´ì •ì™„ë£Œ: {uploaded_file.name}", use_column_width=True)
                res_img = Image.fromarray(result)
                buf = io.BytesIO()
                res_img.save(buf, format="PNG")
                st.download_button(label="ğŸ’¾ ë‹¤ìš´ë¡œë“œ", data=buf.getvalue(), file_name=f"aligned_{uploaded_file.name}", mime="image/png", key=f"dl_{idx}")
            else:
                st.warning(f"{uploaded_file.name}: ì¸ì‹ ì‹¤íŒ¨")
