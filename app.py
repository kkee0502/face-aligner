import streamlit as st
import cv2
import numpy as np
from PIL import Image
import io

def load_ai_engine():
    try:
        import mediapipe as mp
        from mediapipe.solutions import face_mesh as mp_face_mesh
        return mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True)
    except:
        import mediapipe.python.solutions.face_mesh as mp_face_mesh
        return mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True)

st.set_page_config(page_title="No-Distortion Aligner", layout="wide")
st.title("ğŸ“¸ ì™œê³¡ ì—†ëŠ” ì–¼êµ´ ì •ë ¬ê¸°")

if 'engine' not in st.session_state:
    st.session_state.engine = load_ai_engine()
face_mesh = st.session_state.engine

def align_face_no_distortion(img_array):
    if img_array is None: return None
    h, w, _ = img_array.shape
    results = face_mesh.process(cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR))
    
    if not results or not results.multi_face_landmarks:
        return None

    landmarks = results.multi_face_landmarks[0].landmark
    
    # [1] ë‘ ëˆˆì˜ ì¢Œí‘œ ì¶”ì¶œ
    l_eye = np.array([landmarks[33].x * w, landmarks[33].y * h])
    r_eye = np.array([landmarks[263].x * w, landmarks[263].y * h])
    
    # [2] íšŒì „ ê°ë„ ë° ëˆˆ ì‚¬ì´ ê±°ë¦¬ ê³„ì‚°
    dY = r_eye[1] - l_eye[1]
    dX = r_eye[0] - l_eye[0]
    angle = np.degrees(np.arctan2(dY, dX))
    
    # í˜„ì¬ ëˆˆ ì‚¬ì´ ê±°ë¦¬
    current_dist = np.sqrt(dX**2 + dY**2)
    
    # [3] ëª©í‘œ ì„¤ì •
    # ëª¨ë“  ì‚¬ì§„ì˜ ëˆˆ ì‚¬ì´ ê±°ë¦¬ë¥¼ í™”ë©´ ì§§ì€ ìª½ì˜ 30%ë¡œ í†µì¼ (ì–¼êµ´ í¬ê¸° ê³ ì •)
    target_dist = min(h, w) * 0.30
    scale = target_dist / current_dist
    
    # [4] ìœ ì‚¬ ë³€í™˜ í–‰ë ¬ ìƒì„± (íšŒì „ + ë°°ìœ¨ + ì´ë™)
    # ì´ë¯¸ì§€ì˜ í˜•íƒœë¥¼ ì™œê³¡í•˜ì§€ ì•Šê³  íšŒì „ê³¼ í¬ê¸°ë§Œ ì¡°ì ˆí•©ë‹ˆë‹¤.
    eyes_center = ((l_eye[0] + r_eye[0]) // 2, (l_eye[1] + r_eye[1]) // 2)
    M = cv2.getRotationMatrix2D(eyes_center, angle, scale)
    
    # [5] ëˆˆ ìœ„ì¹˜ë¥¼ ì‚¬ì§„ì˜ íŠ¹ì • ì§€ì (ì¤‘ì•™ ìƒë‹¨)ìœ¼ë¡œ ì´ë™ì‹œí‚¤ê¸° ìœ„í•œ ë³´ì •
    tX = w * 0.5
    tY = h * 0.45
    M[0, 2] += (tX - eyes_center[0])
    M[1, 2] += (tY - eyes_center[1])
    
    # ìµœì¢… ë³€í™˜
    aligned_img = cv2.warpAffine(img_array, M, (w, h), borderMode=cv2.BORDER_CONSTANT, borderValue=(0,0,0))
    
    return aligned_img

uploaded_files = st.file_uploader("ì‚¬ì§„ë“¤ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", accept_multiple_files=True)

if uploaded_files:
    cols = st.columns(3)
    for idx, uploaded_file in enumerate(uploaded_files):
        image = Image.open(uploaded_file)
        img_array = np.array(image.convert('RGB'))
        result = align_face_no_distortion(img_array)
        
        with cols[idx % 3]:
            if result is not None:
                st.image(result, caption=f"ì •ë ¬ ì™„ë£Œ: {uploaded_file.name}", use_column_width=True)
                res_img = Image.fromarray(result)
                buf = io.BytesIO()
                res_img.save(buf, format="PNG")
                st.download_button("ğŸ’¾ ë‹¤ìš´ë¡œë“œ", buf.getvalue(), f"aligned_{uploaded_file.name}", "image/png", key=f"dl_{idx}")
