import streamlit as st
import cv2
import numpy as np
from PIL import Image
import io

# [1. AI ì—”ì§„ ë¡œë“œ ë¡œì§]
def load_ai_engine():
    try:
        import mediapipe as mp
        if hasattr(mp, 'solutions'):
            mp_face_mesh = mp.solutions.face_mesh
        else:
            from mediapipe.python.solutions import face_mesh as mp_face_mesh
        return mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True)
    except Exception:
        import mediapipe.python.solutions.face_mesh as mp_face_mesh
        return mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True)

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Face Aligner Pro", layout="wide")
st.title("ğŸ“¸ AI ì–¼êµ´ ê°ë„ ì •ë ¬ê¸° (Pro)")

if 'engine' not in st.session_state:
    try:
        st.session_state.engine = load_ai_engine()
    except Exception as e:
        st.error(f"AI ì—”ì§„ ë¡œë“œ ì‹¤íŒ¨: {e}")
        st.stop()

face_mesh = st.session_state.engine

# [2. ì´ë¯¸ì§€ ì²˜ë¦¬ í•¨ìˆ˜]
def process_face_keep_ratio(img_array):
    if img_array is None: return None
    h, w, _ = img_array.shape
    results = face_mesh.process(cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR))
    
    if not results or not results.multi_face_landmarks:
        return None

    landmarks = results.multi_face_landmarks[0].landmark
    l_eye, r_eye, nose = landmarks[33], landmarks[263], landmarks[1]
    
    # ì¤‘ì‹¬ì  ì¡ê¸°
    center_y = int((l_eye.y + r_eye.y) / 2 * h)
    center_x = int(nose.x * w)
    
    # ì–¼êµ´ í¬ê¸° ì¸¡ì • (ëˆˆ ì‚¬ì´ ê±°ë¦¬ ê¸°ì¤€)
    eye_dist = np.sqrt((l_eye.x - r_eye.x)**2 + (l_eye.y - r_eye.y)**2)
    
    # [ìˆ˜ì •í¬ì¸íŠ¸] ì—¬ë°± ìˆ˜ì¹˜ ì¡°ì ˆ
    # 0.8: ì‹œì›í•œ ì—¬ë°± / 1.0: ì•„ì£¼ ë„“ì€ ì—¬ë°± / 0.5: ì–¼êµ´ ìœ„ì£¼
    zoom_factor = 0.8 / (0.25 / eye_dist)
    
    crop_w = int(w * zoom_factor)
    crop_h = int(h * zoom_factor)
    
    # ì¢Œí‘œ ê³„ì‚°
    y1, y2 = max(0, center_y - crop_h // 2), min(h, center_y + crop_h // 2)
    x1, x2 = max(0, center_x - crop_w // 2), min(w, center_x + crop_w // 2)
    
    return img_array[y1:y2, x1:x2]

# [3. ì›¹ í™”ë©´ UI]
uploaded_files = st.file_uploader("ì‚¬ì§„ë“¤ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", accept_multiple_files=True)

if uploaded_files:
    num_files = len(uploaded_files)
    cols = st.columns(min(num_files, 3))
    
    for idx, uploaded_file in enumerate(uploaded_files):
        image = Image.open(uploaded_file)
        img_array = np.array(image.convert('RGB'))
        result = process_face_keep_ratio(img_array)
        
        with cols[idx % 3]:
            if result is not None:
                # [ì˜¤ë¥˜ í•´ê²°] use_container_width ëŒ€ì‹  use_column_width=True ì‚¬ìš©
                st.image(result, caption=f"ì •ë ¬ë¨: {uploaded_file.name}", use_column_width=True)
                
                res_img = Image.fromarray(result)
                buf = io.BytesIO()
                res_img.save(buf, format="PNG")
                st.download_button(
                    label="ğŸ’¾ ë‹¤ìš´ë¡œë“œ",
                    data=buf.getvalue(),
                    file_name=f"aligned_{uploaded_file.name}",
                    mime="image/png",
                    key=f"btn_{idx}"
                )
            else:
                st.warning(f"{uploaded_file.name}: ì¸ì‹ ì‹¤íŒ¨")
