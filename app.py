import streamlit as st
import cv2
import numpy as np
from PIL import Image
import io

def load_ai_engine():
    import mediapipe as mp
    from mediapipe.solutions import face_mesh as mp_face_mesh
    return mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True)

st.set_page_config(page_title="Portrait Fit Aligner", layout="wide")
st.title("ğŸ” ì–¼êµ´ ë¹„ìœ¨ ìµœì í™”(75%) & ì •ë©´ ê¸°ì¤€ í†µí•© ì •ë ¬ê¸°")
st.write("ì²« ë²ˆì§¸ ì‚¬ì§„(ì •ë©´)ì„ ê¸°ì¤€ìœ¼ë¡œ ì–¼êµ´ì´ í™”ë©´ì˜ ì•½ 3/4ì„ ì°¨ì§€í•˜ë„ë¡ ì¡°ì ˆí•˜ì—¬ ì •ë ¬í•©ë‹ˆë‹¤.")

if 'engine' not in st.session_state:
    st.session_state.engine = load_ai_engine()
face_mesh = st.session_state.engine

if 'base_face_metrics' not in st.session_state:
    st.session_state.base_face_metrics = None

def align_and_fit(img_array, is_first_image):
    if img_array is None: return None
    h, w, _ = img_array.shape
    results = face_mesh.process(cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR))
    
    if not results or not results.multi_face_landmarks:
        return None

    landmarks = results.multi_face_landmarks[0].landmark
    
    # ì£¼ìš” í¬ì¸íŠ¸: ëˆˆì¹ì¤‘ì•™(8), ë¯¸ê°„(6), ì…ìˆ ì¤‘ì•™ì„ (0), ë™ê³µ(468, 473)
    brow = np.array([landmarks[8].x * w, landmarks[8].y * h])
    bridge = np.array([landmarks[6].x * w, landmarks[6].y * h])
    lip = np.array([landmarks[0].x * w, landmarks[0].y * h])
    l_pupil = np.array([landmarks[468].x * w, landmarks[468].y * h])
    r_pupil = np.array([landmarks[473].x * w, landmarks[473].y * h])
    
    # ìˆ˜í‰ ê°ë„
    angle = np.degrees(np.arctan2(r_pupil[1] - l_pupil[1], r_pupil[0] - l_pupil[0]))

    # [ë¡œì§] ì •ë©´ ê¸°ì¤€ ìŠ¤ì¼€ì¼ë§ + ë¹„ìœ¨ ìµœì í™” (í•µì‹¬ ìˆ˜ì •)
    current_v_dist = np.linalg.norm(brow - lip) # í˜„ì¬ ì‚¬ì§„ì˜ ëˆˆì¹-ì…ìˆ  ê±°ë¦¬

    # ëª©í‘œ ë¹„ìœ¨ ì„¤ì •: 'ëˆˆì¹~ì…ìˆ ' ê±°ë¦¬ê°€ ì „ì²´ í™”ë©´ ë†’ì´ì˜ ì•½ 40%ê°€ ë˜ë„ë¡ ì„¤ì •
    # ì´ë ‡ê²Œ í•˜ë©´ ë¨¸ë¦¬ ìœ„ì™€ í„± ì•„ë˜ ì—¬ë°±ì´ ìì—°ìŠ¤ëŸ½ê²Œ í™•ë³´ë˜ì–´ ì–¼êµ´ì´ í™”ë©´ì˜ ì•½ 75% ì •ë„ ì°¨ì§€í•˜ê²Œ ë©ë‹ˆë‹¤.
    target_ratio = 0.40 

    if is_first_image:
        # ì²« ë²ˆì§¸ ì‚¬ì§„(ì •ë©´)ì˜ ì‹¤ì œ ê±°ë¦¬ë¥¼ ê¸°ì¤€ê°’ìœ¼ë¡œ ì €ì¥
        st.session_state.base_face_metrics = {
            'v_dist': current_v_dist,
            'bridge_y_ratio': 0.45 # ë¯¸ê°„ì„ í™”ë©´ì˜ 45% ë†’ì´ì— ë°°ì¹˜ (ì•ˆì •ì ì¸ êµ¬ë„)
        }
        # ì²« ì‚¬ì§„ì˜ ìŠ¤ì¼€ì¼ ê³„ì‚°
        scale = (h * target_ratio) / current_v_dist
    else:
        # ì¸¡ë©´ ì‚¬ì§„ì˜ ê²½ìš°, ì •ë©´ì˜ ì ˆëŒ€ í”½ì…€ ê±°ë¦¬ì— ë§ì¶˜ ë’¤ ëª©í‘œ ë¹„ìœ¨ ì ìš©
        if st.session_state.base_face_metrics:
            base_v_dist = st.session_state.base_face_metrics['v_dist']
            # í˜„ì¬ ì–¼êµ´ì„ ì •ë©´ í¬ê¸°ë¡œ ë§ì¶”ëŠ” ìŠ¤ì¼€ì¼ * ì •ë©´ì„ ëª©í‘œ ë¹„ìœ¨ë¡œ ë§ì¶”ëŠ” ìŠ¤ì¼€ì¼
            scale = (base_v_dist / current_v_dist) * ((h * target_ratio) / base_v_dist)
        else:
            scale = (h * target_ratio) / current_v_dist # ê¸°ì¤€ ì—†ìœ¼ë©´ ìì²´ ë¹„ìœ¨ ì ìš©

    # ë³€í™˜ í–‰ë ¬ ìƒì„± (ë¯¸ê°„ ì¤‘ì‹¬)
    M = cv2.getRotationMatrix2D(tuple(bridge), angle, scale)

    # ë¯¸ê°„ ìœ„ì¹˜ ê°•ì œ ê³ ì • (ì •ë©´ ê¸°ì¤€ ë¹„ìœ¨ ì ìš©)
    t_bridge = M @ np.array([bridge[0], bridge[1], 1])
    target_y = st.session_state.base_face_metrics['bridge_y_ratio'] * h if st.session_state.base_face_metrics else h * 0.45
    
    M[0, 2] += (w * 0.5 - t_bridge[0])  # ê°€ë¡œ ì¤‘ì•™
    M[1, 2] += (target_y - t_bridge[1]) # ì„¸ë¡œ ì •ë©´ ê¸°ì¤€ ê³ ì •

    # ì´ë¯¸ì§€ ì›Œí•‘ (ì—¬ë°±ì€ ê°€ì¥ìë¦¬ í”½ì…€ ë³µì‚¬ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì±„ì›€)
    aligned_img = cv2.warpAffine(img_array, M, (w, h), borderMode=cv2.BORDER_REPLICATE)
    return aligned_img

# --- UI ë¶€ë¶„ ---
uploaded_files = st.file_uploader("ì •ë©´ ì‚¬ì§„ë¶€í„° ìˆœì„œëŒ€ë¡œ ì—…ë¡œë“œí•˜ì„¸ìš”", accept_multiple_files=True)

if uploaded_files:
    show_guide = st.checkbox("ê°€ì´ë“œë¼ì¸ í‘œì‹œ (ëˆˆì¹-ë¯¸ê°„-ì…ìˆ )", value=True)
    cols = st.columns(len(uploaded_files))
    
    for idx, uploaded_file in enumerate(uploaded_files):
        image = Image.open(uploaded_file)
        img_array = np.array(image.convert('RGB'))
        
        # ì²« ë²ˆì§¸ ì‚¬ì§„ ì—¬ë¶€ ì „ë‹¬
        result = align_and_fit(img_array, is_first_image=(idx == 0))
        
        with cols[idx]:
            if result is not None:
                # resultì—ì„œ ì§ì ‘ ë†’ì´(res_h)ì™€ ë„ˆë¹„(res_w)ë¥¼ ê°€ì ¸ì™€ ì—ëŸ¬ ë°©ì§€
                res_h, res_w = result.shape[:2]
                
                if show_guide:
                    # ìµœì í™”ëœ ë¹„ìœ¨ì— ë§ì¶˜ ê°€ì´ë“œ ë¼ì¸ (ëˆˆì¹, ë¯¸ê°„, ì…ìˆ )
                    # ëˆˆì¹(brow_y) = bridge_y - (target_ratio * 0.5 * h) ê·¼ì²˜
                    # ì…ìˆ (lip_y) = bridge_y + (target_ratio * 0.5 * h) ê·¼ì²˜
                    # ìˆ˜í•™ì  ë¹„ë¡€ì— ë”°ë¼ ê³„ì‚°ëœ ê°€ì´ë“œë¼ì¸ ìœ„ì¹˜
                    bridge_y_ratio = st.session_state.base_face_metrics['bridge_y_ratio'] if st.session_state.base_face_metrics else 0.45
                    
                    # ëˆˆì¹(ì´ˆë¡), ë¯¸ê°„(ë¹¨ê°•), ì…ìˆ (í•˜ëŠ˜)
                    # ë¹„ìœ¨ì€ ë¯¸ê°„ ê³ ì •ì (0.45)ì„ ê¸°ì¤€ìœ¼ë¡œ ëˆˆì¹~ì…ìˆ  ê±°ë¦¬(0.40)ì˜ ì ˆë°˜ì”© ê°€ê°
                    guide_y_ratios = [bridge_y_ratio - target_ratio/2, bridge_y_ratio, bridge_y_ratio + target_ratio/2]
                    colors = [(0, 255, 0), (255, 0, 0), (0, 255, 255)]
                    
                    for ratio, color in zip(guide_y_ratios, colors):
                        y_pos = int(res_h * ratio)
                        cv2.line(result, (0, y_pos), (res_w, y_pos), color, 2)
                
                st.image(result, caption=f"Aligned: {uploaded_file.name}", use_column_width=True)
                
                res_img = Image.fromarray(result)
                buf = io.BytesIO()
                res_img.save(buf, format="PNG")
                st.download_button("ğŸ’¾", buf.getvalue(), f"fit_{uploaded_file.name}", "image/png", key=f"dl_{idx}")
