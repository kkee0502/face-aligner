import streamlit as st
import cv2
import numpy as np
from PIL import Image
import io

def load_ai_engine():
    import mediapipe as mp
    return mp.solutions.face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True)

st.set_page_config(page_title="Ultimate Frame & Face Sync", layout="wide")
st.title("ğŸ“¸ ê¸°ê³„ í”„ë ˆì„ & ì•ˆë©´ ë¼ì¸ ì™„ì „ ë™ê¸°í™”")

if 'engine' not in st.session_state:
    st.session_state.engine = load_ai_engine()
face_mesh = st.session_state.engine

def align_image_final(img_array):
    if img_array is None: return None
    h, w, _ = img_array.shape
    
    # [1] ê¸°ê³„ ê³ ì • ì¥ì¹˜(í•˜ì–€ìƒ‰ í”„ë ˆì„ ë° ë…¹ìƒ‰ í•€) ê°ì§€ ë¡œì§
    hsv = cv2.cvtColor(img_array, cv2.COLOR_RGB2HSV)
    # ë…¹ìƒ‰ í•€ ì¸ì‹ ë²”ìœ„ ì •ë°€í™”
    lower_green = np.array([40, 40, 40])
    upper_green = np.array([80, 255, 255])
    mask = cv2.inRange(hsv, lower_green, upper_green)
    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # [2] ì•ˆë©´ ëœë“œë§ˆí¬ ì¶”ì¶œ
    results = face_mesh.process(cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR))
    
    # --- Case A: ê¸°ê³„ê°€ ê°ì§€ëœ ê²½ìš° (ê¸°ê³„ ê¸°ì¤€ ì •ë ¬) ---
    if len(contours) >= 1:
        # ê°€ì¥ í° ì»¨íˆ¬ì–´(ë…¹ìƒ‰ í•€)ì˜ ì¤‘ì‹¬ì  ê³„ì‚°
        c = max(contours, key=cv2.contourArea)
        M_cnt = cv2.moments(c)
        if M_cnt["m00"] != 0:
            cX = int(M_cnt["m10"] / M_cnt["m00"])
            cY = int(M_cnt["m01"] / M_cnt["m00"])
            
            # ê¸°ê³„ ì‚¬ì§„ì€ íšŒì „í•˜ì§€ ì•Šê³ (ê¸°ê³„ ìì²´ê°€ ìˆ˜í‰ì´ë¯€ë¡œ) ìœ„ì¹˜ë§Œ ê³ ì •
            # ê¸°ê³„ ê³ ì •í•€ ìœ„ì¹˜ë¥¼ í™”ë©´ì˜ (75%, 50%) ì§€ì ìœ¼ë¡œ ê³ ì •
            target_x, target_y = w * 0.75, h * 0.50
            M = np.float32([[1, 0, target_x - cX], [0, 1, target_y - cY]])
            return cv2.warpAffine(img_array, M, (w, h))

    # --- Case B: ê¸°ê³„ê°€ ì—†ê±°ë‚˜ ì¸ì‹ì´ ì•ˆ ëœ ê²½ìš° (ì–¼êµ´ ê¸°ì¤€ ì •ë ¬) ---
    if results.multi_face_landmarks:
        landmarks = results.multi_face_landmarks[0].landmark
        
        # ê¸°ì¤€ì  (ëˆˆ ì•ˆìª½, ë¯¸ê°„, í„±)
        l_eye = np.array([landmarks[133].x * w, landmarks[133].y * h])
        r_eye = np.array([landmarks[362].x * w, landmarks[362].y * h])
        bridge = np.array([landmarks[6].x * w, landmarks[6].y * h])
        chin = np.array([landmarks[152].x * w, landmarks[152].y * h])
        
        # 1. ê°ë„: ëˆˆ ìˆ˜í‰
        angle = np.degrees(np.arctan2(r_eye[1] - l_eye[1], r_eye[0] - l_eye[0]))
        
        # 2. ë°°ìœ¨: ì¸¡ë©´ ì–¼êµ´ì´ ì»¤ì§€ëŠ” ê²ƒì„ ë§‰ê¸° ìœ„í•´ ìˆ˜ì§ ê±°ë¦¬ë¥¼ ê°•ì œ ê³ ì •
        curr_h = np.linalg.norm(bridge - chin)
        eye_dist = np.linalg.norm(r_eye - l_eye)
        is_profile = (eye_dist / curr_h) < 0.55
        
        # ì¸¡ë©´ì¼ ë•Œ ë°°ìœ¨ì„ 25% ë” ì¶•ì†Œí•˜ì—¬ ì •ë©´ ë©´ì ê³¼ ë§ì¶¤
        target_h = h * 0.30
        scale = (target_h / curr_h) * (0.75 if is_profile else 1.0)
        
        M = cv2.getRotationMatrix2D(tuple(bridge), angle, scale)
        
        # 3. ìœ„ì¹˜: í„±ê³¼ ëˆˆì¹ ë¼ì¸ ë™ê¸°í™”
        # í„± ìœ„ì¹˜ë¥¼ í™”ë©´ 70% ì§€ì ì— ê°•ì œ ê³ ì • (ì¸¡ë©´ì€ ê¸°í•˜í•™ì  ë³´ì •ìœ¼ë¡œ 67%ì— ë°°ì¹˜)
        t_chin_y = h * 0.67 if is_profile else h * 0.70
        curr_chin_trans = M @ np.array([chin[0], chin[1], 1])
        
        M[0, 2] += (w * 0.5 - curr_chin_trans[0])
        M[1, 2] += (t_chin_y - curr_chin_trans[1])
        
        return cv2.warpAffine(img_array, M, (w, h))

    return img_array

uploaded_files = st.file_uploader("ì‚¬ì§„ë“¤ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", accept_multiple_files=True)

if uploaded_files:
    cols = st.columns(3)
    for idx, f in enumerate(uploaded_files):
        img = Image.open(f)
        img_arr = np.array(img.convert('RGB'))
        res = align_image_final(img_arr)
        with cols[idx % 3]:
            st.image(res, caption=f"ì •ë ¬ë¨: {f.name}")
            buf = io.BytesIO(); Image.fromarray(res).save(buf, format="PNG")
            st.download_button("ğŸ’¾", buf.getvalue(), f"res_{f.name}", "image/png", key=idx)
