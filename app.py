import streamlit as st
import cv2
import numpy as np
from PIL import Image
import io

def load_ai_engine():
    try:
        import mediapipe as mp
        from mediapipe.solutions import face_mesh as mp_face_mesh
        return mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True)
    except:
        import mediapipe.python.solutions.face_mesh as mp_face_mesh
        return mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True)

st.set_page_config(page_title="Line-Lock Aligner Pro", layout="wide")
st.title("ğŸ“¸ ì •ë©´ ëœë“œë§ˆí¬ ê¸°ì¤€ ì¸¡ëª¨ ì •ë°€ ì •ë ¬ê¸°")
st.write("ì •ë©´ ì‚¬ì§„ì˜ ëœë“œë§ˆí¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì¸¡ëª¨ ì‚¬ì§„ì˜ ì‚¬ì´ì¦ˆë¥¼ ì¡°ì ˆí•˜ê³  ê³ ì •í•©ë‹ˆë‹¤.")

if 'engine' not in st.session_state:
    st.session_state.engine = load_ai_engine()
face_mesh = st.session_state.engine

# ì •ë©´ ì‚¬ì§„ ëœë“œë§ˆí¬ ì €ì¥ì„ ìœ„í•œ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'frontal_landmarks' not in st.session_state:
    st.session_state.frontal_landmarks = None

def get_landmarks(img_array):
    if img_array is None: return None
    h, w, _ = img_array.shape
    results = face_mesh.process(cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR))
    
    if not results or not results.multi_face_landmarks:
        return None

    return results.multi_face_landmarks[0].landmark

def align_precise_line_lock(img_array, frontal_landmarks=None):
    if img_array is None: return None
    h, w, _ = img_array.shape
    results = face_mesh.process(cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR))
    
    if not results or not results.multi_face_landmarks:
        return None

    landmarks = results.multi_face_landmarks[0].landmark
    
    # 4ëŒ€ í•µì‹¬ í¬ì¸íŠ¸ ì¶”ì¶œ
    # 1. ì •ìˆ˜ë¦¬ (10ë²ˆ)
    top_head = np.array([landmarks[10].x * w, landmarks[10].y * h])
    # 2. ëˆˆì¹ ì¤‘ì•™ (8ë²ˆ)
    brow_mid = np.array([landmarks[8].x * w, landmarks[8].y * h])
    # 3. ë¯¸ê°„ (6ë²ˆ)
    bridge = np.array([landmarks[6].x * w, landmarks[6].y * h])
    # 4. ì…ìˆ  ìƒë‹¨ ì¤‘ì•™ (0ë²ˆ + ì¸¡ë©´ ë³´ì •)
    lip_top_x, lip_top_y = landmarks[0].x * w, landmarks[0].y * h
    
    # ì¸¡ë©´ íŒë³„ ë° ì…ìˆ ì„  ë³´ì • (ì¸¡ëª¨ì—ì„œ ì…ìˆ ì´ ë‚®ê²Œ ì¡íˆëŠ” í˜„ìƒ ë°©ì§€)
    l_eye = np.array([landmarks[33].x * w, landmarks[33].y * h])
    r_eye = np.array([landmarks[263].x * w, landmarks[263].y * h])
    eye_dist = np.linalg.norm(l_eye - r_eye)
    face_height = np.linalg.norm(bridge - np.array([lip_top_x, lip_top_y]))
    is_profile = (eye_dist / face_height) < 0.5
    
    if is_profile:
        # ì¸¡ë©´ì¼ ê²½ìš° ì…ìˆ  ì£¼ë³€ ìœ¤ê³½ í¬ì¸íŠ¸(11, 12, 16)ë¥¼ ì°¸ì¡°í•˜ì—¬ ì…ìˆ ì„  ìœ„ì¹˜ ìƒí–¥ ë³´ì •
        lip_top_y = (landmarks[0].y * 0.4 + landmarks[11].y * 0.2 + landmarks[12].y * 0.2 + landmarks[16].y * 0.2) * h

    lip_top = np.array([lip_top_x, lip_top_y])

    # ìˆ˜í‰ ê°ë„ ê³„ì‚° (ë™ê³µ ê¸°ì¤€)
    angle = np.degrees(np.arctan2(r_eye[1] - l_eye[1], r_eye[0] - l_eye[0]))

    # í†µí•© ìŠ¤ì¼€ì¼ ê³„ì‚° (ì •ë©´ ëœë“œë§ˆí¬ ê¸°ì¤€ ì •ë°€ ì¡°ì •)
    # ì •ë©´ ëœë“œë§ˆí¬ê°€ ì œê³µëœ ê²½ìš°, ì •ìˆ˜ë¦¬~ì…ìˆ ì„  ê±°ë¦¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìŠ¤ì¼€ì¼ì„ ì¡°ì •í•©ë‹ˆë‹¤.
    if frontal_landmarks is not None:
        frontal_top_head = np.array([frontal_landmarks[10].x * w, frontal_landmarks[10].y * h])
        frontal_lip_top = np.array([frontal_landmarks[0].x * w, frontal_landmarks[0].y * h])
        target_full_len = np.linalg.norm(frontal_top_head - frontal_lip_top)
    else:
        # ì •ë©´ ëœë“œë§ˆí¬ê°€ ì—†ëŠ” ê²½ìš°, ê¸°ë³¸ ë¹„ìœ¨(í™”ë©´ ë†’ì´ì˜ 50%)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
        target_full_len = h * 0.50

    current_full_len = np.linalg.norm(top_head - lip_top)
    scale = target_full_len / current_full_len

    # ë³€í™˜ í–‰ë ¬ ìƒì„± (íšŒì „ ì¤‘ì‹¬ì€ ë¯¸ê°„)
    M = cv2.getRotationMatrix2D(tuple(bridge), angle, scale)

    # 4ì  ë¼ì¸ ê³ ì • (Line-Lock) ë¡œì§ (ì •ë©´ ë¯¸ê°„ ìœ„ì¹˜ ê¸°ì¤€)
    # ì •ë©´ ë¯¸ê°„ ìœ„ì¹˜ê°€ ì œê³µëœ ê²½ìš°, ë³€í™˜ëœ ë¯¸ê°„ ìœ„ì¹˜ë¥¼ í™•ì¸í•˜ê³  ì •ë©´ ë¯¸ê°„ y ì¢Œí‘œì— ê°•ì œ ê³ ì •í•©ë‹ˆë‹¤.
    curr_bridge_trans = M @ np.array([bridge[0], bridge[1], 1])
    
    # ê°€ë¡œ ì¤‘ì•™ ì •ë ¬
    M[0, 2] += (w * 0.5 - curr_bridge_trans[0])
    
    if frontal_landmarks is not None:
        # ì„¸ë¡œ ë¯¸ê°„ ê³ ì • (ì •ë©´ ë¯¸ê°„ y ì¢Œí‘œ ê¸°ì¤€)
        frontal_bridge_y = frontal_landmarks[6].y * h
        M[1, 2] += (frontal_bridge_y - curr_bridge_trans[1])
    else:
        # ì •ë©´ ë¯¸ê°„ ìœ„ì¹˜ê°€ ì—†ëŠ” ê²½ìš°, ê¸°ë³¸ ë¹„ìœ¨(45% ì§€ì )ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
        M[1, 2] += (h * 0.45 - curr_bridge_trans[1])

    # ì´ë¯¸ì§€ ìƒì„± ë° ì—¬ë°± ë³µì‚¬ (ê²€ì€ ì—¬ë°± ì œê±°)
    aligned_img = cv2.warpAffine(img_array, M, (w, h), 
                                 borderMode=cv2.BORDER_REPLICATE)
    
    return aligned_img

# --- UI ë ˆì´ì•„ì›ƒ ---
uploaded_files = st.file_uploader("ì‚¬ì§„ë“¤ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (ì²« ë²ˆì§¸ ì‚¬ì§„ì€ ì •ë©´ ì‚¬ì§„ì´ì–´ì•¼ í•©ë‹ˆë‹¤)", accept_multiple_files=True)

if uploaded_files:
    # ê°€ì´ë“œ ë¼ì¸ í‘œì‹œ ì—¬ë¶€ - ì‚¬ìš©ì ê°€ì‹œì„±ì„ ìœ„í•´ ì¶”ê°€
    show_guide = st.checkbox("4ëŒ€ ê¸°ì¤€ì„  í‘œì‹œ (í™•ì¸ìš©)", value=True)
    
    cols = st.columns(len(uploaded_files))
    for idx, uploaded_file in enumerate(uploaded_files):
        image = Image.open(uploaded_file)
        img_array = np.array(image.convert('RGB'))
        
        # ì²« ë²ˆì§¸ ì‚¬ì§„ì„ ì •ë©´ ì‚¬ì§„ìœ¼ë¡œ ê°„ì£¼í•˜ê³  ëœë“œë§ˆí¬ ì¶”ì¶œ ë° ì €ì¥
        if idx == 0:
            st.session_state.frontal_landmarks = get_landmarks(img_array)
            result = align_precise_line_lock(img_array)
        else:
            # ë‘ ë²ˆì§¸ ì‚¬ì§„ë¶€í„°ëŠ” ì •ë©´ ëœë“œë§ˆí¬ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
            result = align_precise_line_lock(img_array, st.session_state.frontal_landmarks)
        
        with cols[idx]:
            if result is not None:
                if show_guide:
                    # ëª¨ë“  ì‚¬ì§„ì—ì„œ ì´ ìœ„ì¹˜ì— í¬ì¸íŠ¸ë“¤ì´ ì˜¤ê²Œ ë©ë‹ˆë‹¤.
                    lines = [0.22, 0.38, 0.45, 0.72] # ì •ìˆ˜ë¦¬, ëˆˆì¹, ë¯¸ê°„, ì…ìˆ ì„  ë¹„ìœ¨
                    colors = [(255,200,0), (0,255,0), (255,0,0), (0,200,255)]
                    for line_y, color in zip(lines, colors):
                        cv2.line(result, (0, int(h*line_y)), (w, int(h*line_y)), color, 2)
                
                st.image(result, caption=f"4ì  ì •ë ¬: {uploaded_file.name}", use_column_width=True)
                
                # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                res_img = Image.fromarray(result)
                buf = io.BytesIO()
                res_img.save(buf, format="PNG")
                st.download_button("ğŸ’¾ ë‹¤ìš´ë¡œë“œ", buf.getvalue(), f"locked_{uploaded_file.name}", "image/png", key=f"dl_{idx}")
