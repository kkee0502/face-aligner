import streamlit as st
import cv2
import numpy as np
from PIL import Image
import io

def load_ai_engine():
    import mediapipe as mp
    from mediapipe.solutions import face_mesh as mp_face_mesh
    return mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True)

st.set_page_config(page_title="Frontal-Base Aligner", layout="wide")
st.title("ğŸ“¸ ì •ë©´ ê¸°ì¤€ ì¸¡ëª¨ ê°•ì œ ê³ ì • ì •ë ¬ê¸°")
st.write("ì²« ë²ˆì§¸ ì‚¬ì§„(ì •ë©´)ì˜ ì´ëª©êµ¬ë¹„ í¬ê¸°ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ëª¨ë“  ì‚¬ì§„ì„ ë§ì¶¥ë‹ˆë‹¤.")

if 'engine' not in st.session_state:
    st.session_state.engine = load_ai_engine()
face_mesh = st.session_state.engine

# ì •ë©´ ì‚¬ì§„ì˜ ê¸°ì¤€ ë°ì´í„° ì €ì¥ì„ ìœ„í•œ ì„¸ì…˜ ìƒíƒœ
if 'base_face_metrics' not in st.session_state:
    st.session_state.base_face_metrics = None

def align_to_frontal_base(img_array, is_first_image):
    if img_array is None: return None
    h, w, _ = img_array.shape
    results = face_mesh.process(cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR))
    
    if not results or not results.multi_face_landmarks:
        return None

    landmarks = results.multi_face_landmarks[0].landmark
    
    # ì•µì»¤ í¬ì¸íŠ¸ ì¶”ì¶œ: ëˆˆì¹ì¤‘ì•™(8), ë¯¸ê°„(6), ì…ìˆ ì¤‘ì•™ì„ (0)
    brow = np.array([landmarks[8].x * w, landmarks[8].y * h])
    bridge = np.array([landmarks[6].x * w, landmarks[6].y * h])
    lip = np.array([landmarks[0].x * w, landmarks[0].y * h])
    
    # ìˆ˜í‰ ê°ë„ (ë™ê³µ ê¸°ì¤€)
    l_pupil = np.array([landmarks[468].x * w, landmarks[468].y * h])
    r_pupil = np.array([landmarks[473].x * w, landmarks[473].y * h])
    angle = np.degrees(np.arctan2(r_pupil[1] - l_pupil[1], r_pupil[0] - l_pupil[0]))

    # [í•µì‹¬ ë¡œì§] ì •ë©´ ê¸°ì¤€ ìŠ¤ì¼€ì¼ë§
    current_v_dist = np.linalg.norm(brow - lip) # í˜„ì¬ ì‚¬ì§„ì˜ ëˆˆì¹-ì…ìˆ  ê±°ë¦¬

    if is_first_image:
        # ì²« ë²ˆì§¸ ì‚¬ì§„(ì •ë©´)ì˜ ì‹¤ì œ ê±°ë¦¬ë¥¼ ê¸°ì¤€ê°’ìœ¼ë¡œ ì €ì¥
        st.session_state.base_face_metrics = {
            'v_dist': current_v_dist,
            'bridge_y_ratio': bridge[1] / h  # ì •ë©´ì˜ ë¯¸ê°„ ë†’ì´ ë¹„ìœ¨ ì €ì¥
        }
        scale = 1.0
    else:
        # ì¸¡ë©´ ì‚¬ì§„ì˜ ê²½ìš°, ì •ë©´ì˜ 'ëˆˆì¹-ì…ìˆ ' ê¸¸ì´ì— ë§ì¶° ìì‹ ì˜ ì‚¬ì´ì¦ˆë¥¼ ì¡°ì ˆ
        if st.session_state.base_face_metrics:
            scale = st.session_state.base_face_metrics['v_dist'] / current_v_dist
        else:
            scale = 1.0

    # ë³€í™˜ í–‰ë ¬ ìƒì„± (ì½”ë ëŒ€ì‹  ë¯¸ê°„ì„ íšŒì „ì¶•ìœ¼ë¡œ ì‚¬ìš©)
    M = cv2.getRotationMatrix2D(tuple(bridge), angle, scale)

    # ì •ë©´ì˜ ë¯¸ê°„ ë†’ì´ì— ì¸¡ë©´ì˜ ë¯¸ê°„ì„ ê°•ì œ ê³ ì •
    t_bridge = M @ np.array([bridge[0], bridge[1], 1])
    target_y = st.session_state.base_face_metrics['bridge_y_ratio'] * h if st.session_state.base_face_metrics else h * 0.45
    
    M[0, 2] += (w * 0.5 - t_bridge[0])  # ê°€ë¡œ ì¤‘ì•™
    M[1, 2] += (target_y - t_bridge[1]) # ì„¸ë¡œ ì •ë©´ ê¸°ì¤€ ê³ ì •

    aligned_img = cv2.warpAffine(img_array, M, (w, h), borderMode=cv2.BORDER_REPLICATE)
    return aligned_img

uploaded_files = st.file_uploader("ì‚¬ì§„ë“¤ì„ ì—…ë¡œë“œí•˜ì„¸ìš” (ì²« ì‚¬ì§„ì´ ì •ë©´)", accept_multiple_files=True)

if uploaded_files:
    show_guide = st.checkbox("ì •ë©´ ê¸°ì¤€ ë¼ì¸ í‘œì‹œ", value=True)
    cols = st.columns(len(uploaded_files))
    
    for idx, uploaded_file in enumerate(uploaded_files):
        image = Image.open(uploaded_file)
        img_array = np.array(image.convert('RGB'))
        
        # ì²« ë²ˆì§¸ ì‚¬ì§„ ì—¬ë¶€ ì „ë‹¬
        result = align_to_frontal_base(img_array, is_first_image=(idx == 0))
        
        with cols[idx]:
            if result is not None:
                # [ì—ëŸ¬ ìˆ˜ì •] resultì—ì„œ ì§ì ‘ ë†’ì´(res_h)ì™€ ë„ˆë¹„(res_w)ë¥¼ ê°€ì ¸ì˜´
                res_h, res_w = result.shape[:2]
                
                if show_guide:
                    # ì •ë©´ì—ì„œ ì •í•´ì§„ ë¹„ìœ¨ì— ë§ì¶° ë¼ì¸ ë Œë”ë§
                    guide_y = [0.35, 0.42, 0.45, 0.70] # ëˆˆì¹, ë™ê³µ, ë¯¸ê°„, ì…ìˆ 
                    colors = [(0,255,0), (255,255,0), (255,0,0), (0,255,255)]
                    for ratio, color in zip(guide_y, colors):
                        y_pos = int(res_h * ratio)
                        cv2.line(result, (0, y_pos), (res_w, y_pos), color, 2)
                
                st.image(result, caption=f"ì •ë ¬ë¨: {uploaded_file.name}", use_column_width=True)
                
                res_img = Image.fromarray(result)
                buf = io.BytesIO()
                res_img.save(buf, format="PNG")
                st.download_button("ğŸ’¾", buf.getvalue(), f"locked_{uploaded_file.name}", "image/png", key=f"dl_{idx}")
