import streamlit as st
import cv2
import numpy as np
from PIL import Image
import io

# [1. AI ì—”ì§„ ë¡œë“œ] - ë°°í¬ í™˜ê²½ì— ìµœì í™”ëœ ê²½ë¡œë¡œ ì„¤ì •
def load_ai_engine():
    try:
        import mediapipe as mp
        from mediapipe.solutions import face_mesh as mp_face_mesh
        return mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True)
    except:
        import mediapipe.python.solutions.face_mesh as mp_face_mesh
        return mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True)

st.set_page_config(page_title="Universal Face Aligner", layout="wide")
st.title("ğŸ“¸ AI ì „ê°ë„ ì–¼êµ´ ì •ë ¬ê¸°")
st.write("ì •ë©´, ë¯¸ì†Œ, ì¸¡ë©´ ì‚¬ì§„ê¹Œì§€ ì–¼êµ´ í¬ê¸°ì™€ ë†’ì´ë¥¼ ì¼ì •í•˜ê²Œ ë§ì¶¥ë‹ˆë‹¤.")

if 'engine' not in st.session_state:
    st.session_state.engine = load_ai_engine()

face_mesh = st.session_state.engine

# [2. í•µì‹¬ ì •ë ¬ í•¨ìˆ˜]
def align_face_universal(img_array):
    if img_array is None: return None
    h, w, _ = img_array.shape
    
    # AI ì¸ì‹ (BGR ë³€í™˜ í•„ìš”)
    results = face_mesh.process(cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR))
    
    if not results or not results.multi_face_landmarks:
        return None

    landmarks = results.multi_face_landmarks[0].landmark
    
    # ê¸°ì¤€ì  ì¶”ì¶œ: ì¸¡ë©´ì—ì„œë„ ë³€í•˜ì§€ ì•ŠëŠ” ìˆ˜ì§ì¶• ê¸°ì¤€
    l_eye = np.array([landmarks[33].x * w, landmarks[33].y * h])   # ì™¼ìª½ ëˆˆ
    r_eye = np.array([landmarks[263].x * w, landmarks[263].y * h]) # ì˜¤ë¥¸ìª½ ëˆˆ
    nose_bridge = np.array([landmarks[6].x * w, landmarks[6].y * h]) # ë¯¸ê°„ (ì¤‘ì‹¬ì¶•)
    chin = np.array([landmarks[152].x * w, landmarks[152].y * h])    # í„±ë
    
    # 1. íšŒì „ ê°ë„ ê³„ì‚° (ë‘ ëˆˆì˜ ìˆ˜í‰ ìœ ì§€)
    dY = r_eye[1] - l_eye[1]
    dX = r_eye[0] - l_eye[0]
    angle = np.degrees(np.arctan2(dY, dX))
    
    # 2. ë°°ìœ¨ ê³„ì‚° (ì¸¡ë©´ ëŒ€ì‘ í•µì‹¬)
    # ê°€ë¡œ(ëˆˆ ì‚¬ì´ ê±°ë¦¬) ëŒ€ì‹  ìˆ˜ì§(ë¯¸ê°„~í„±) ê¸¸ì´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë°°ìœ¨ì„ ì„¤ì •í•©ë‹ˆë‹¤.
    face_height_pixel = np.sqrt((nose_bridge[0] - chin[0])**2 + (nose_bridge[1] - chin[1])**2)
    
    # ì‚¬ì§„ ë†’ì´ì˜ 35%ë¥¼ ì–¼êµ´ ìˆ˜ì§ ê¸¸ì´ë¡œ ê³ ì • (ëª¨ë“  ì‚¬ì§„ì˜ ì–¼êµ´ í¬ê¸° í†µì¼)
    target_face_height = h * 0.35 
    scale = target_face_height / face_height_pixel
    
    # 3. ìœ ì‚¬ ë³€í™˜ í–‰ë ¬ ìƒì„± (ì™œê³¡ ì—†ì´ íšŒì „+ë°°ìœ¨+ì´ë™)
    # ì¤‘ì‹¬ì ì€ ì–¼êµ´ì˜ ê¸°ë‘¥ì¸ ë¯¸ê°„ìœ¼ë¡œ ì¡ìŠµë‹ˆë‹¤.
    M = cv2.getRotationMatrix2D(tuple(nose_bridge), angle, scale)
    
    # 4. ìœ„ì¹˜ ê³ ì • (ì‚¬ì§„ì˜ ìˆ˜í‰ ì¤‘ì•™, ìˆ˜ì§ 40% ì§€ì ì— ë¯¸ê°„ ê³ ì •)
    tX = w * 0.5
    tY = h * 0.40
    M[0, 2] += (tX - nose_bridge[0])
    M[1, 2] += (tY - nose_bridge[1])
    
    # ìµœì¢… ë³€í™˜ ì‹¤í–‰ (ê²€ì€ ì—¬ë°± ì²˜ë¦¬)
    aligned_img = cv2.warpAffine(img_array, M, (w, h), borderMode=cv2.BORDER_CONSTANT, borderValue=(0,0,0))
    
    return aligned_img

# [3. UI ë° íŒŒì¼ ì²˜ë¦¬]
uploaded_files = st.file_uploader("ì‚¬ì§„ë“¤ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", accept_multiple_files=True)

if uploaded_files:
    cols = st.columns(3)
    for idx, uploaded_file in enumerate(uploaded_files):
        image = Image.open(uploaded_file)
        img_array = np.array(image.convert('RGB'))
        
        # ì •ë ¬ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
        result = align_face_universal(img_array)
        
        with cols[idx % 3]:
            if result is not None:
                # ê²°ê³¼ ì¶œë ¥ (ë¹„ìœ¨ ìœ ì§€)
                st.image(result, caption=f"ì •ë ¬ë¨: {uploaded_file.name}", use_column_width=True)
                
                # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                res_img = Image.fromarray(result)
                buf = io.BytesIO()
                res_img.save(buf, format="PNG")
                st.download_button(
                    label="ğŸ’¾ ë‹¤ìš´ë¡œë“œ",
                    data=buf.getvalue(),
                    file_name=f"aligned_{uploaded_file.name}",
                    mime="image/png",
                    key=f"dl_{idx}"
                )
            else:
                st.warning(f"{uploaded_file.name}: ì–¼êµ´ ì¸ì‹ ì‹¤íŒ¨")
