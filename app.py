import streamlit as st
import cv2
import numpy as np
from PIL import Image
import io

def load_ai_engine():
    import mediapipe as mp
    from mediapipe.solutions import face_mesh as mp_face_mesh
    return mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True)

st.set_page_config(page_title="Portrait Fit Aligner", layout="wide")
st.title("ğŸ” ì–¼êµ´ 75% ìµœì í™” & ì •ë©´ ê¸°ì¤€ í†µí•© ì •ë ¬ê¸°")
st.write("ì²« ë²ˆì§¸ ì‚¬ì§„(ì •ë©´)ì˜ ì´ëª©êµ¬ë¹„ í¬ê¸°ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ëª¨ë“  ì‚¬ì§„ì„ 75% ë¹„ìœ¨ë¡œ ë§ì¶¥ë‹ˆë‹¤.")

if 'engine' not in st.session_state:
    st.session_state.engine = load_ai_engine()
face_mesh = st.session_state.engine

# ì „ì—­ ìƒìˆ˜ ì„¤ì • (í•¨ìˆ˜ ì•ˆíŒì—ì„œ ê³µí†µ ì‚¬ìš©)
TARGET_FACE_RATIO = 0.40  # ëˆˆì¹~ì…ìˆ  ê±°ë¦¬ê°€ í™”ë©´ ë†’ì´ì˜ 40% (ì–¼êµ´ ì „ì²´ëŠ” ì•½ 75% ì°¨ì§€)

if 'base_face_metrics' not in st.session_state:
    st.session_state.base_face_metrics = None

def align_and_fit(img_array, is_first_image):
    if img_array is None: return None
    h, w, _ = img_array.shape
    results = face_mesh.process(cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR))
    
    if not results or not results.multi_face_landmarks:
        return None

    landmarks = results.multi_face_landmarks[0].landmark
    
    # ì£¼ìš” í¬ì¸íŠ¸ ì¶”ì¶œ
    brow = np.array([landmarks[8].x * w, landmarks[8].y * h])
    bridge = np.array([landmarks[6].x * w, landmarks[6].y * h])
    lip = np.array([landmarks[0].x * w, landmarks[0].y * h])
    l_pupil = np.array([landmarks[468].x * w, landmarks[468].y * h])
    r_pupil = np.array([landmarks[473].x * w, landmarks[473].y * h])
    
    angle = np.degrees(np.arctan2(r_pupil[1] - l_pupil[1], r_pupil[0] - l_pupil[0]))
    current_v_dist = np.linalg.norm(brow - lip)

    if is_first_image:
        # ì²« ì‚¬ì§„ ê¸°ì¤€ê°’ ì €ì¥
        st.session_state.base_face_metrics = {
            'v_dist': current_v_dist,
            'bridge_y_ratio': 0.45  # ë¯¸ê°„ ë†’ì´ ê³ ì •
        }
        scale = (h * TARGET_FACE_RATIO) / current_v_dist
    else:
        # ì •ë©´ ê¸°ì¤€ì— ë§ì¶° ì¸¡ë©´ ì‚¬ì§„ ìŠ¤ì¼€ì¼ ì¡°ì •
        if st.session_state.base_face_metrics:
            base_v_dist = st.session_state.base_face_metrics['v_dist']
            scale = (base_v_dist / current_v_dist) * ((h * TARGET_FACE_RATIO) / base_v_dist)
        else:
            scale = (h * TARGET_FACE_RATIO) / current_v_dist

    M = cv2.getRotationMatrix2D(tuple(bridge), angle, scale)
    t_bridge = M @ np.array([bridge[0], bridge[1], 1])
    target_y = st.session_state.base_face_metrics['bridge_y_ratio'] * h if st.session_state.base_face_metrics else h * 0.45
    
    M[0, 2] += (w * 0.5 - t_bridge[0])
    M[1, 2] += (target_y - t_bridge[1])

    aligned_img = cv2.warpAffine(img_array, M, (w, h), borderMode=cv2.BORDER_REPLICATE)
    return aligned_img

# --- UI ë¶€ë¶„ ---
uploaded_files = st.file_uploader("ì •ë©´ ì‚¬ì§„ë¶€í„° ì—…ë¡œë“œí•˜ì„¸ìš”", accept_multiple_files=True)

if uploaded_files:
    show_guide = st.checkbox("ê°€ì´ë“œë¼ì¸ í‘œì‹œ (ëˆˆì¹-ë¯¸ê°„-ì…ìˆ )", value=True)
    cols = st.columns(len(uploaded_files))
    
    for idx, uploaded_file in enumerate(uploaded_files):
        image = Image.open(uploaded_file)
        img_array = np.array(image.convert('RGB'))
        
        result = align_and_fit(img_array, is_first_image=(idx == 0))
        
        with cols[idx]:
            if result is not None:
                res_h, res_w = result.shape[:2]
                
                if show_guide:
                    # ì„¸ì…˜ê³¼ ìƒìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì•ˆì „í•˜ê²Œ ê°€ì´ë“œë¼ì¸ ê³„ì‚°
                    b_y_ratio = st.session_state.base_face_metrics['bridge_y_ratio'] if st.session_state.base_face_metrics else 0.45
                    
                    # ë¼ì¸ ìœ„ì¹˜: ëˆˆì¹, ë¯¸ê°„, ì…ìˆ 
                    guide_lines = [b_y_ratio - TARGET_FACE_RATIO/2, b_y_ratio, b_y_ratio + TARGET_FACE_RATIO/2]
                    colors = [(0, 255, 0), (255, 0, 0), (0, 255, 255)]
                    
                    for r, color in zip(guide_lines, colors):
                        y_pos = int(res_h * r)
                        cv2.line(result, (0, y_pos), (res_w, y_pos), color, 2)
                
                st.image(result, caption=uploaded_file.name, use_column_width=True)
                
                res_img = Image.fromarray(result)
                buf = io.BytesIO()
                res_img.save(buf, format="PNG")
                st.download_button("ğŸ’¾", buf.getvalue(), f"final_{uploaded_file.name}", "image/png", key=f"dl_{idx}")
