import streamlit as st
import cv2
import numpy as np
from PIL import Image
import io

def load_ai_engine():
    try:
        import mediapipe as mp
        from mediapipe.solutions import face_mesh as mp_face_mesh
        return mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True)
    except:
        import mediapipe.python.solutions.face_mesh as mp_face_mesh
        return mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True)

st.set_page_config(page_title="Final Chin-Line Sync", layout="wide")
st.title("ğŸ“¸ ì „ê°ë„ í„± ë¼ì¸ ì¼ì¹˜ ì •ë ¬ê¸°")

if 'engine' not in st.session_state:
    st.session_state.engine = load_ai_engine()
face_mesh = st.session_state.engine

def align_face_fixed_line(img_array):
    if img_array is None: return None
    h, w, _ = img_array.shape
    results = face_mesh.process(cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR))
    
    if not results or not results.multi_face_landmarks:
        return None

    landmarks = results.multi_face_landmarks[0].landmark
    
    # 1. ì •ë°€ ê¸°ì¤€ì  ì¶”ì¶œ
    l_eye_inner = np.array([landmarks[133].x * w, landmarks[133].y * h])
    r_eye_inner = np.array([landmarks[362].x * w, landmarks[362].y * h])
    nose_bridge = np.array([landmarks[6].x * w, landmarks[6].y * h]) # ë¯¸ê°„
    chin = np.array([landmarks[152].x * w, landmarks[152].y * h])    # í„±ë
    
    # 2. íšŒì „ ê°ë„ ê³„ì‚° (ëˆˆ ìˆ˜í‰ ìœ ì§€)
    dY = r_eye_inner[1] - l_eye_inner[1]
    dX = r_eye_inner[0] - l_eye_inner[0]
    angle = np.degrees(np.arctan2(dY, dX))
    
    # 3. ë°°ìœ¨ ê²°ì • (ìˆ˜ì§ ê¸°ë‘¥ ê¸°ì¤€)
    face_height_pixel = np.sqrt((nose_bridge[0] - chin[0])**2 + (nose_bridge[1] - chin[1])**2)
    
    # ì¸¡ë©´ íŒë³„ (ëˆˆ ë„ˆë¹„ ë¹„ìœ¨)
    eye_dist = np.sqrt(dX**2 + dY**2)
    is_profile = (eye_dist / face_height_pixel) < 0.52
    
    # [ìˆ˜ì •] ì¸¡ë©´ ë°°ìœ¨ì„ ë” ê³¼ê°í•˜ê²Œ ì¶•ì†Œ (0.72) í•˜ì—¬ ì •ë©´ê³¼ ë©´ì ì„ ë§ì¶¤
    profile_scale_fix = 0.72 if is_profile else 1.0
    target_face_height = h * 0.28  # ì–¼êµ´ í¬ê¸° í‘œì¤€í™”
    scale = (target_face_height / face_height_pixel) * profile_scale_fix
    
    # 4. ë³€í™˜ í–‰ë ¬ ìƒì„±
    M = cv2.getRotationMatrix2D(tuple(nose_bridge), angle, scale)
    
    # [5. í„± ë¼ì¸ ê°•ì œ ì¼ì¹˜ ë¡œì§]
    # ëª¨ë“  ì‚¬ì§„ì˜ í„±(Chin) ëì´ í™”ë©´ ìƒë‹¨ì—ì„œ ì •í™•íˆ 68% ì§€ì ì— ì˜¤ë„ë¡ ì„¤ì •
    # ì¸¡ë©´ì¼ ë•Œ í„±ì´ ë” ë‚´ë ¤ì˜¤ëŠ” í˜„ìƒì„ ë§‰ê¸° ìœ„í•´ target_yë¥¼ ì¸ìœ„ì ìœ¼ë¡œ ìƒí–¥ ì¡°ì •
    target_chin_y = h * 0.64 if is_profile else h * 0.68
    target_chin_x = w * 0.5
    
    # ë³€í™˜ í›„ì˜ í˜„ì¬ í„± ìœ„ì¹˜ ê³„ì‚°
    curr_chin_trans = M @ np.array([chin[0], chin[1], 1])
    
    # í„±ì˜ ì˜¤ì°¨ë§Œí¼ ì „ì²´ ì´ë¯¸ì§€ë¥¼ ìˆ˜ì§/ìˆ˜í‰ ì´ë™
    M[0, 2] += (target_chin_x - curr_chin_trans[0])
    M[1, 2] += (target_chin_y - curr_chin_trans[1])
    
    aligned_img = cv2.warpAffine(img_array, M, (w, h), borderMode=cv2.BORDER_CONSTANT, borderValue=(0,0,0))
    
    return aligned_img

uploaded_files = st.file_uploader("ì‚¬ì§„ë“¤ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", accept_multiple_files=True)

if uploaded_files:
    cols = st.columns(len(uploaded_files))
    for idx, uploaded_file in enumerate(uploaded_files):
        image = Image.open(uploaded_file)
        img_array = np.array(image.convert('RGB'))
        result = align_face_fixed_line(img_array)
        
        with cols[idx]:
            if result is not None:
                st.image(result, caption=f"ì •ë ¬ë¨: {uploaded_file.name}", use_column_width=True)
                res_img = Image.fromarray(result)
                buf = io.BytesIO()
                res_img.save(buf, format="PNG")
                st.download_button("ğŸ’¾ ë‹¤ìš´ë¡œë“œ", buf.getvalue(), f"final_{uploaded_file.name}", "image/png", key=f"dl_{idx}")
