import streamlit as st
import cv2
import numpy as np
from PIL import Image
import io

def load_ai_engine():
    try:
        import mediapipe as mp
        from mediapipe.solutions import face_mesh as mp_face_mesh
        return mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True)
    except:
        import mediapipe.python.solutions.face_mesh as mp_face_mesh
        return mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True)

st.set_page_config(page_title="Precision Face Aligner", layout="wide")
st.title("ğŸ“¸ AI ì–¼êµ´ ì •ë°€ ë™ê¸°í™” ì •ë ¬ê¸°")

if 'engine' not in st.session_state:
    st.session_state.engine = load_ai_engine()
face_mesh = st.session_state.engine

def align_precision(img_array):
    if img_array is None: return None
    h, w, _ = img_array.shape
    results = face_mesh.process(cv2.cvtColor(img_array, cv2.COLOR_RGB2BGR))
    
    if not results or not results.multi_face_landmarks:
        return None

    landmarks = results.multi_face_landmarks[0].landmark
    
    # 1. ê¸°ì¤€ì  ì¶”ì¶œ
    l_eye = np.array([landmarks[33].x * w, landmarks[33].y * h])
    r_eye = np.array([landmarks[263].x * w, landmarks[263].y * h])
    nose_bridge = np.array([landmarks[6].x * w, landmarks[6].y * h]) # ë¯¸ê°„
    chin = np.array([landmarks[152].x * w, landmarks[152].y * h])    # í„±ë
    
    # 2. íšŒì „ ê°ë„ ê³„ì‚° (ëˆˆ ìˆ˜í‰ ìœ ì§€)
    dY = r_eye[1] - l_eye[1]
    dX = r_eye[0] - l_eye[0]
    angle = np.degrees(np.arctan2(dY, dX))
    
    # 3. ë°°ìœ¨ ê²°ì • ë° ì¸¡ë©´ ë³´ì •
    face_height_pixel = np.sqrt((nose_bridge[0] - chin[0])**2 + (nose_bridge[1] - chin[1])**2)
    
    # ì •ë©´/ì¸¡ë©´ íŒë³„ ê³„ìˆ˜ (ëˆˆ ë„ˆë¹„ì™€ ì–¼êµ´ ë†’ì´ ë¹„ìœ¨)
    eye_dist = np.sqrt(dX**2 + dY**2)
    side_factor = eye_dist / face_height_pixel 
    
    # [í•µì‹¬ ë³´ì •] ì¸¡ë©´(side_factor < 0.5)ì¼ìˆ˜ë¡ ë°°ìœ¨ì„ ë” ë§ì´ ê¹ì•„ì„œ ì •ë©´ê³¼ í¬ê¸°ë¥¼ ë§ì¶¤
    # ì •ë©´ì€ 1.0, ì¸¡ë©´ì¼ìˆ˜ë¡ 0.82ê¹Œì§€ ë°°ìœ¨ì„ ì¤„ì„
    profile_compensation = 1.0 if side_factor > 0.55 else 0.82
    
    target_face_height = h * 0.30 # ì „ì²´ í™”ë©´ì˜ 30%ë¥¼ ì–¼êµ´ ë†’ì´ë¡œ ì„¤ì •
    scale = (target_face_height / face_height_pixel) * profile_compensation
    
    # 4. ë³€í™˜ í–‰ë ¬ ìƒì„±
    M = cv2.getRotationMatrix2D(tuple(nose_bridge), angle, scale)
    
    # [5. í„± ë†’ì´ ê°•ì œ ì¼ì¹˜ ë¡œì§]
    # ëª¨ë“  ì‚¬ì§„ì—ì„œ í„±(Chin)ì˜ Yì¶• ìœ„ì¹˜ë¥¼ í™”ë©´ ìƒë‹¨ì—ì„œ 65% ì§€ì ìœ¼ë¡œ ê³ ì •
    # ì •ë©´/ì¸¡ë©´ ëª¨ë‘ ë™ì¼í•œ ìˆ˜í‰ì„ ìƒì— í„±ì´ ì˜¤ê²Œ ë©ë‹ˆë‹¤.
    target_chin_y = h * 0.65
    target_chin_x = w * 0.5
    
    # í˜„ì¬ í„± ìœ„ì¹˜ê°€ ë³€í™˜ í›„ ì–´ë””ë¡œ ê°€ëŠ”ì§€ ê³„ì‚°
    curr_chin_transformed = M @ np.array([chin[0], chin[1], 1])
    
    # ëª©í‘œ í„± ìœ„ì¹˜ì™€ì˜ ì˜¤ì°¨ë§Œí¼ ì „ì²´ ì´ë¯¸ì§€ë¥¼ ìˆ˜ì§/ìˆ˜í‰ ì´ë™
    M[0, 2] += (target_chin_x - curr_chin_transformed[0])
    M[1, 2] += (target_chin_y - curr_chin_transformed[1])
    
    aligned_img = cv2.warpAffine(img_array, M, (w, h), borderMode=cv2.BORDER_CONSTANT, borderValue=(0,0,0))
    
    return aligned_img

uploaded_files = st.file_uploader("ì‚¬ì§„ë“¤ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", accept_multiple_files=True)

if uploaded_files:
    cols = st.columns(3)
    for idx, uploaded_file in enumerate(uploaded_files):
        image = Image.open(uploaded_file)
        img_array = np.array(image.convert('RGB'))
        result = align_precision(img_array)
        
        with cols[idx % 3]:
            if result is not None:
                st.image(result, caption=f"ì •ë ¬ ì™„ë£Œ: {uploaded_file.name}", use_column_width=True)
                res_img = Image.fromarray(result)
                buf = io.BytesIO()
                res_img.save(buf, format="PNG")
                st.download_button(label="ğŸ’¾ ë‹¤ìš´ë¡œë“œ", data=buf.getvalue(), file_name=f"aligned_{uploaded_file.name}", mime="image/png", key=f"dl_{idx}")
            else:
                st.warning(f"{uploaded_file.name}: ì¸ì‹ ì‹¤íŒ¨")
